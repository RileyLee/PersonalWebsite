<!DOCTYPE html>
<html>


<link rel="stylesheet" href="css/main.css">

<style>

    ul {
        list-style-type: none;
        margin: 0;
            padding: 0;
            overflow: hidden;
            background: linear-gradient(to bottom right, #181818, #919191);
    }

    li {
    float: left;
    }

    li a {
    display: block;
    color: white;
    text-align: center;
    padding: 14px 16px;
    text-decoration: none;
    }

    li a:hover {
    background-color: #111;
    }
</style>

<head>
    <title>Yuguang Li - Personal Website</title>
</head>


<body>

<ul>
    <li><a class="active" href="#Home">Home</a></li>
    <li><a href="#Projects">Projects</a></li>
    <li><a href="#Contact">Contact</a></li>
</ul>

<h1>

    Yuguang Li (Riley)
    <img src="pics/AdamSummit.jpg" alt="Adam Summit" align="right" style="width:600px;height:180px;vertical-align: top;">
    <a href="http://grail.cs.washington.edu/"; target="_blank"; class="link"; float = right; >
        <img src="pics/UW_CSE.png" alt="fb" style="width:140px;height:140px; vertical-align: top;">
    </a>
    <p style="font-size : 15px; align:top;">ylee3@cs.washington.edu</p>

</h1>

<a href="https://github.com/RileyLee"; target="_blank"; class="link"; float = right;>
    <img src="pics/GitHub-Mark.png" alt="github" style="width:40px;height:40px; ">
</a>

<a href="https://www.linkedin.com/in/yuguang-lee-48700a58"; target="_blank"; class="link"; float = right;>
    <img src="pics/LinkedIn_logo.png" alt="fb" style="width:40px;height:40px;">
</a>

<a href="files/Yuguang_CV.pdf"; target="_blank"; class="link"; float = right;>
    <img src="pics/resume.png" alt="fb" style="width:40px;height:40px;">
</a>



<p class = "subtitle"; style = "color : #424242"> Image Engineer / Computer Graphics / Image Recognition / PhD student at University of Washington </p>

<h2>Summary</h2>
<p class = "summary">
    I'm a 2nd-year PhD student working on computer vision and computer graphics from University of Washington. My interests
    are mainly about image object detection, computer graphics, ray-tracing, high-performance image processing and artificial
    intelligence. I'm looking for a software engineer position preferably doing vision related projects.
    <a href="files/Yuguang_CV.pdf"; target="_blank"; class="link-db"; float = right; style = "font-weight:bold">
        Resume
    </a>
</p>
<hr>

<h2>Project</h2>
<h3>Cross-platform Halide-based Image Processing Pipeline</h3>
<p class = "project">
    I built a Halide-based cross-platform fast image processing solution to simplify hardware acceleration coding in
    image processing. With out framework built on OpenGL Halide, GPU and CPU
    image processing programs could be easily accelerated from scheduling. Meanwhile, Halide compiles them on all kind
    of hardware platforms, iOS, Android, windows, webs apps and etc. During the project, I helped improve the Halide library with OpenGL.
    In the meantime, I invented several new filters, such as graphic novel, pop-art and halftone.
    Photoshop Express and Aviary have already been using our solution in their products.
</p>

<h3>Multi-angle Environmental Matting and Interpolation</h3>
<a href="http://homes.cs.washington.edu/~ylee3/EnviMatting/EnviMatting.html" target="_blank" class="link">
    http://homes.cs.washington.edu/~ylee3/EnviMatting/EnviMatting.html
</a>
<p class = "project">
    Matting and compositing a reflective/refractive object like a glass cup into a new environment and make it look
    realistic from different perspectives is an interesting generalization of traditional greenscreen matting. Douglas
    introduced the environment matting method to simulate reflection/refraction effect for single perspective. To solve
    our multi-view environment matting problem, we implemented the traditional single-image environment method and
    incorporated interpolation to generate environment matting for unseen perspectives. Experiments using DSLR images
    and iPhone videos demonstrate promising results for both single-view environment matting and interpolation. We also
    did experiments with Lytro-Illum camera and structure from motion to calibrate camera positions. They didn't turn
    out to be successful but is a great lesson to learn.
</p>

<h3>Mitosis recognition from histopathological images</h3>
<p class = "project">
    The count of mitosis existing in histopathological images is widely used in cancer diagnosis. So far, mitosis are
    mainly picked out visually by experienced technicians. The existing computer algorithm is mainly built on either
    deep leaning neural network or feature classifier with handcrafted feature selection and extraction method. In this
    project, I'm working on improving the state-of-art algorithm by merging these two mainstream methods above together.
    By using object segmentation, computer is able to find mitosis faster. In the meantime, handcrafted features
    contributes to a higher recognition accuracy.
</p>

<h3>CVPR 2016 face recognition challenge</h3>
<a href="http://gesture.chalearn.org/2016-looking-at-people-cvpr-challenge" target="_blank" class="link">
    https://competitions.codalab.org/competitions/8421#learn_the_details
</a>
<p class = "project">
    We built a face detector and classifier to recognize gender and facial expression in the contest datasets. The
    overall accuracy of predicting gender and facial expressions are 81% and 89%.
    Our team Let's face it (2 members, me and Deepali Aneja) ranks #5 of 77 teams with 84.7% overall accuracy on
    detecting facial expressions and gender detection. We'll make a web page for this very soon!! Click on this
    <a href="http://sergioescalera.com/wp-content/uploads/2016/05/18.pdf" target="_blank" class="link_db"> link </a>
    here for the official results.
</p>



<h3>Zooplankton recognition using deep learning neural network</h3>
<p class = "project">
    In this project, I worked on classifying grayscale images of plankton. They were created using scanners on sea-water
    samples. Each slide contains thousands of targets of different species. The target size is generally 1 - 5mm. The
    resulting plankton densities of different species are then used by scientists to analyze the fish production.
    Specifically, I'm trying to develop a rotation invariant deep learning convolution neural network model, which
    combines different handcrafted color and texture features to classify different species and their different phase.
    I'm also going to explore an optimized pipeline to efficiently select and scan the region of interest.
</p>

<hr>

<h2>Project Gallery</h2>
<p>
    My first annimator project with the R2D2 model designed by me in OpenGL. Check this
    <a href="https://github.com/RileyLee/AnimatorR2D2" target="_blank" class="link">
        link
    </a>
    for more detail on github.
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/5AaO7iHM_4w" frameborder="0" allowfullscreen></iframe>

<hr>

<h2>Publications</h2>
<p>
    The impact of sensor field-of-view and distance on field measurements of directional reflectance factors: A simulation
    study for row crops
    <br />
    Journal: Remote Sensing of Environment (Impact Factor: 5.103)
    <br /><br />

    GPU-based acceleration for Monte Carlo ray-tracing of complex 3D scene
    <br />
    Geoscience and Remote Sensing Symposium (IGARSS), 2012 IEEE International / ISSN: 2153-6996
    <br /><br />

    A Computer Simulation Model to Compute the Radiation Transfer of Mountainous Regions
    <br />
    Proceeding of SPIE Conference on Remote Sensing 2011/Proc. SPIE 8174, 817426 (2011)
    <br /><br />

    A Radiosity-based Model to Compute the Radiation Transfer of Soil Surface
    <br />
    Proceeding of SPIE Conference on Remote Sensing 2011/Proc. SPIE 8174, 81742G (2011)
    <br /><br />
</p>


</body>
</html>