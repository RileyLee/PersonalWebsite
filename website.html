<!DOCTYPE html>
<html>

<link rel="stylesheet" href="css/main.css">

<style>

    ul {
        list-style-type: none;
        margin: 0;
            padding: 0;
            overflow: hidden;
            background: linear-gradient(to bottom right, #181818, #181818);
    }

    li {
    float: left;
    }

    li a {
    display: block;
    color: white;
    text-align: center;
    padding: 14px 16px;
    text-decoration: none;
    }

    li a:hover {
    background-color: #ffe901;
    }
</style>

<head>
    <title>Yuguang Li - Personal Website</title>
</head>



<body style="margin-left: 20px; width : 100%">


<ul>
    <li><a href="#Projects">Projects</a></li>
    <li><a href="#Gallery">Gallery</a></li>
    <li><a href="#Publication">Publication</a></li>
</ul>


<div style="position: relative; top : 0px; bottom : 0px;">
<div style="position: relative; top : 40px; bottom : -50px; ">

    <h1 >
        <div style="position: relative; left : 0px; bottom : 0px; font-family:'Helvetica Neue'">
            Yuguang Li (Riley)
        </div>
        <div style="position: relative; top: -30px; left : 300px; bottom : 0px;">
            <a href="http://grail.cs.washington.edu/"; target="_blank"; class="link"; float = right; >
                <img src="pics/UW_CSE.png" alt="fb" style="width:140px; height:140px; vertical-align: top;">
                <img src="pics/AdamSummit.jpg" alt="Adam Summit" style="width:580px;height:172px;vertical-align: top;">
            </a>
        </div>
        <div style="position: relative; top : -160px; left : 10px; bottom : -120px;">
            <p style="font-size : 15px; align:top; width : 300px; font-family:'Helvetica'; line-height:130%; color : #575757">
                402 Paul G. Allen Center for Computer Science & Engineering,
                West Stevens Way Northeast
                Seattle, WA 98195
            </p>
            <p style="font-size : 15px; align:top; font-family:'Helvetica'; line-height:130%; color : #575757">
                Email : ylee3@cs.washington.edu
            </p>
        </div>

    </h1>
    <div style="position: relative; top : -140px; bottom : 0px;">
        <div style="position: relative; left : 20px; bottom : 0px;">
            <a href="https://github.com/RileyLee"; target="_blank"; class="link"; float = right;>
                <img src="pics/GitHub-Mark.png" alt="github" style="width:40px;height:40px; ">
            </a>

            <a href="https://www.linkedin.com/in/yuguang-lee-48700a58"; target="_blank"; class="link"; float = right;>
                <img src="pics/LinkedIn_logo.png" alt="fb" style="width:40px;height:40px;">
            </a>

            <a href="files/Yuguang_CV.pdf"; target="_blank"; class="link"; float = right;>
                <img src="pics/resume.png" alt="fb" style="width:40px;height:40px;">
            </a>
        </div>
        <div style="position: relative; left : 20px; bottom : 0px;">
            <p class = "subtitle"; style = "color : #000000; font-family:'Optima';"> Image Engineer / Computer Graphics / Image Recognition / PhD student at University of Washington </p>
        </div>
    </div>
</div>


<div style="position: relative; top : -70px; bottom : 0px; text-align : justify;">
    <h2>Summary</h2>
    <p class = "summary">
        <blockquote>
            I'm a 2nd-year PhD student advised by Professor
            <a href="http://homes.cs.washington.edu/~shapiro/" target="_blank">
                Linda Shapiro
            </a>
            from University of Washington. I'm a part of the
            <a href="http://grail.cs.washington.edu/" target="_blank">
                GRAIL
            </a>
             lab in UW CSE. I'm interested
            in image object detection, computer graphics, ray-tracing, high-performance image processing and artificial
            intelligence. I'm looking for a software engineer position preferably doing vision related projects.
            <a href="files/Yuguang_CV.pdf"; target="_blank"; class="link-db"; float = right; style = "font-weight:bold">
                Resume
            </a>
        </blockquote>
    </p>
    <hr>
</div>

<div style="position: relative; top : -60px; bottom : 0px;">
    <h2 position = relative; top = 0px; bottom = 0px>Project</h2>

    <div style="position: relative; top : 10px; text-align : justify;">
        <h3>Cross-platform Halide-based Image Processing Pipeline</h3>
        <p class = "project">
            <div style="position: relative; top : -5px; ">
                <blockquote>
                    I built a Halide-based cross-platform fast image processing solution to simplify hardware acceleration coding in
                    image processing. With out framework built on OpenGL Halide, GPU and CPU
                    image processing programs could be easily accelerated from scheduling. Meanwhile, Halide compiles them on all kind
                    of hardware platforms, iOS, Android, windows, webs apps and etc. During the project, I helped improve the Halide library with OpenGL.
                    In the meantime, I invented several new filters, such as graphic novel, pop-art and halftone.
                    Photoshop Express and Aviary have already been using our solution in their products.
                </blockquote>
            </div>
        </p>
    </div>


    <div style="position: relative; top : 10px; text-align : justify;">
        <h3>Multi-view Environmental Matting and Interpolation</h3>
        <div style="position: relative; top : -5px; text-align : justify;">
            <blockquote>
                <div>
                <p class = "project" style = "text-align : justify;">
                    Matting and compositing a reflective/refractive object like a glass cup into a new environment and make it look
                    realistic from different perspectives is an interesting generalization of traditional greenscreen matting. Douglas
                    introduced the environment matting method to simulate reflection/refraction effect for single perspective. To solve
                    our multi-view environment matting problem, we implemented the traditional single-image environment method and
                    incorporated interpolation to generate environment matting for unseen perspectives. Experiments using DSLR images
                    and iPhone videos demonstrate promising results for both single-view environment matting and interpolation. We also
                    did experiments with Lytro-Illum camera and structure from motion to calibrate camera positions. They didn't turn
                    out to be successful but is a great lesson to learn.
                </p>
                    </div>
                <div style="position: relative; top : -15px; ">
                    <a href="http://homes.cs.washington.edu/~ylee3/EnviMatting/EnviMatting.html" target="_blank">
                        http://homes.cs.washington.edu/~ylee3/EnviMatting/EnviMatting.html
                    </a>
                </div>



            </blockquote>
        </div>
    </div>

    <div style="position: relative; top : -10px; text-align : justify;">
        <h3>C++ based photon mapping engine for simulating flurescent effects in vegetation canopies</h3>
        <div style="position: relative; top : -5px; ">
            <blockquote>

                <p class = "project" style = "text-align : justify;">
                    I built a ray-tracing (photon-mapping) physical engine to precisely simulate the generation and transmission of multi-spectral fluorescent effect
                    in dense vegetation canopies (Plant fluorescent effect has been proved very accurate in indicating plant health condition).
                    Compared to the traditional ray-tracing engines, this engine works with high precision and efficiency in the situation
                    where most of the spectrum energy is reflected by diffusion, also the sensors (airborne cameras) are limited by very tiny field of view angles.
                    In order to achieve this, I implemented GPU acceleration with openCL on CUDA architecture. The Monte Carlo chain is also
                    optimized by improved sampling techniques. This research leads to multiple
                    <a href="#Publication" >publications</a>, where we're still working on paper of simulating fluorescent effects.
                </p>
            </blockquote>
        </div>
    </div>

    <div style="position: relative; top : -10px; text-align : justify;">
        <h3>Mitosis recognition from histopathological images</h3>
        <div style="position: relative; top : -5px; ">
            <blockquote>
                <p class = "project" style = "text-align : justify;">
                    The count of mitosis existing in histopathological images is widely used in cancer diagnosis. So far, mitosis are
                    mainly picked out visually by experienced technicians. The existing computer algorithm is mainly built on either
                    deep leaning neural network or feature classifier with handcrafted feature selection and extraction method. In this
                    project, I'm working on improving the state-of-art algorithm by merging these two mainstream methods above together.
                    By using object segmentation, computer is able to find mitosis faster. In the meantime, handcrafted features
                    contributes to a higher recognition accuracy.
                </p>
            </blockquote>
        </div>
    </div>

    <div style="position: relative; top : -10px; text-align : justify;">
        <h3>CVPR 2016 face recognition challenge</h3>

        <div style="position: relative; top : -5px; ">
            <blockquote>
                <p class = "project" style = "text-align : justify;">
                    We built a face detector and classifier to recognize gender and facial expression in the contest datasets. The
                    overall accuracy of predicting gender and facial expressions are 81% and 89%.
                    Our team Let's face it (2 members, me and
                    <a href="http://homes.cs.washington.edu/~deepalia/" target="_blank">
                        Deepali Aneja
                    </a>
                    ) ranks #5 of 77 teams with 84.7% overall accuracy on
                    detecting facial expressions and gender detection. We'll make a web page for this very soon!! Click on this
                    <a href="http://sergioescalera.com/wp-content/uploads/2016/05/18.pdf" target="_blank" class="link_db"> link </a>
                    here for the official results.
                </p>
                <div style="position: relative; top : -15px; ">
                    <a href="http://gesture.chalearn.org/2016-looking-at-people-cvpr-challenge" target="_blank">
                        https://competitions.codalab.org/competitions/8421#learn_the_details
                    </a>
                </div>
            </blockquote>
        </div>
    </div>


    <div style="position: relative; top : -30px; text-align : justify;">
        <h3>Zooplankton recognition using deep learning neural network</h3>
        <div style="position: relative; top : -5px; ">
            <blockquote>
                <p class = "project" style = "text-align : justify;">
                    In this project, I worked on classifying grayscale images of plankton. They were created using scanners on sea-water
                    samples. Each slide contains thousands of targets of different species. The target size is generally 1 - 5mm. The
                    resulting plankton densities of different species are then used by scientists to analyze the fish production.
                    Specifically, I'm trying to develop a rotation invariant deep learning convolution neural network model, which
                    combines different handcrafted color and texture features to classify different species and their different phase.
                    I'm also going to explore an optimized pipeline to efficiently select and scan the region of interest.
                </p>
            </blockquote>
        </div>
    </div>


    <hr>
    <A NAME="Gallery">
    <h2>Project Gallery</h2>
        <div style="position: relative; left : 20px">
            <p>
                My first annimator project with my self-designed R2D2 model in OpenGL. Check this
                <a href="https://github.com/RileyLee/AnimatorR2D2" target="_blank" class="link">
                    link
                </a>
                for more detail on github.
            </p>
            <div style="position: relative; left : 20px">
            <iframe width="560" height="315" src="https://www.youtube.com/embed/5AaO7iHM_4w" frameborder="0" allowfullscreen></iframe>
            </div>
        </div>

        <div style="position: relative; left : 20px; top : 20px">
            <p style="width : 1000px">
                My Environmental Matting & scene interpolation demo video. This video is generated using two matting pictures. Click the
                <a href="http://homes.cs.washington.edu/~ylee3/EnviMatting/EnviMatting.html" target="_blank" class="link">
                    link
                </a>
                for more detail on our project page.
            </p>
        </div>

        <div style="position: relative; left : 0px; top : 20px">
            <figure>
                <video controls="" class="centered_full" width="58%" >
                    <source src="videos/InterpV_Gopro3.mov">
                </video>
            </figure>
        </div>

        <div style="position: relative; left : 20px; top : 40px">
            <p style="width : 1000px">
                Picture of Stolkholm before and after Oilpaint filter from chipp (Adobe summer project). The whole 500 * 600 image takes iPhone6s GPU 5ms to process. I'm going to make a video soon.
            </p>
            <div style="position: relative; left : 20px; top : 0px">
                <img src="pics/stolkholm.jpg" alt="original" style="width:40%; vertical-align: top;">
                <img src="pics/chipp_stockholm.png" alt="oilpaint" style="width:42.8%;vertical-align: top;">
            </div>
            <p style="position: relative; left : 20px; top : -5px">
                Photo credit : Hunter Mask ;)
            </p>
        </div>


    </A>

    <div style="position: relative; left : 0px; top : 20px">
    <hr>

    <a href="#" class="scrollup">Scroll</a>
    

    <A NAME="Publication">

        <h2>Publications</h2>
        <p>
            <li type="square" style="position: relative; left : 20px">
                The impact of sensor field-of-view and distance on field measurements of directional reflectance factors: A simulation
                study for row crops
                <br />
                Journal: Remote Sensing of Environment 156 (2014): 129-142.
            <br /><br />
            </li>

            <li type="square" style="position: relative; left : 20px">
                GPU-based acceleration for Monte Carlo ray-tracing of complex 3D scene
                <br />
                Geoscience and Remote Sensing Symposium (IGARSS), 2012 IEEE International / ISSN: 2153-6996
                <br /><br />
            </li>

            <li type="square" style="position: relative; left : 20px">
                A Computer Simulation Model to Compute the Radiation Transfer of Mountainous Regions
                <br />
                Proceeding of SPIE Conference on Remote Sensing 2011/Proc. SPIE 8174, 817426 (2011)
                <br /><br />
            </li>

            <li type="square" style="position: relative; left : 20px">
                A Radiosity-based Model to Compute the Radiation Transfer of Soil Surface
                <br />
                Proceeding of SPIE Conference on Remote Sensing 2011/Proc. SPIE 8174, 81742G (2011)
                <br /><br />
            </li>
        </p>
    </A>
        </div>
</div>
</body>
    </div>
</html>